# RSAR_kinematics
Predict camera 6-DOF pose from 2-DOF pan/tilt input using a multi-task LSTM-Attention model
ì•„ë˜ëŠ” ë‹¹ì‹ ì´ ì œê³µí•œ **3ê°œì˜ ì£¼ìš” Python ì½”ë“œ (`train_multitask_attention_LSTM.py`, `eval_multitask_attention_LSTM.py`, `exportResultExcel.py`)**,
`dataset.txt`, ê·¸ë¦¬ê³  **conda í™˜ê²½ ì •ë³´**ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •ë¦¬í•œ GitHubìš© `README.md` ì´ˆì•ˆì…ë‹ˆë‹¤.

ì´ íŒŒì¼ì€ ë°”ë¡œ GitHubì— ì—…ë¡œë“œí•˜ê±°ë‚˜ ë³µì‚¬í•´ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

```markdown
# ğŸ¯ Multi-Task Attention LSTM for Camera Pose Estimation

ì´ í”„ë¡œì íŠ¸ëŠ” **ë‹¤ì¤‘ ì‘ì—… ê¸°ë°˜ì˜ Attention LSTM ëª¨ë¸**ì„ ì‚¬ìš©í•˜ì—¬  
ì…ë ¥ëœ **ì‹œì  ì •ë³´(p, t)**ë¡œë¶€í„° **ì¹´ë©”ë¼ ìœ„ì¹˜(Position)**ì™€ **íšŒì „(Rotation)**ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤.  
PyTorch ê¸°ë°˜ì˜ Transformer-like êµ¬ì¡°ë¥¼ ì´ìš©í•´ **ì •í™•í•œ ì¹´ë©”ë¼ íŒŒë¼ë¯¸í„° ì¶”ì •**ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

---

## ğŸ“‚ Repository Structure

```

â”œâ”€â”€ train_multitask_attention_LSTM.py   # ëª¨ë¸ í•™ìŠµ (í›ˆë ¨ìš©)
â”œâ”€â”€ eval_multitask_attention_LSTM.py    # ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ë° ê²°ê³¼ ì¶œë ¥
â”œâ”€â”€ exportResultExcel.py                # AI ë° Classical ëª¨ë¸ ê²°ê³¼ Excel ë‚´ë³´ë‚´ê¸°
â”œâ”€â”€ dataset.txt                         # ì…ë ¥ ë°ì´í„° (id, p_deg, t_deg, camPos, camEuler)
â”œâ”€â”€ scalers/                            # í•™ìŠµ ì¤‘ ì €ì¥ë˜ëŠ” í‘œì¤€í™” ìŠ¤ì¼€ì¼ëŸ¬
â”‚   â”œâ”€â”€ scaler_x.pkl
â”‚   â””â”€â”€ scaler_pos.pkl
â””â”€â”€ best_model_sequential.pth           # í›ˆë ¨ ì™„ë£Œëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ (ìë™ ì €ì¥)

````

---

## ğŸ§  Model Overview

ë³¸ ëª¨ë¸ì€ **ë‹¤ì¤‘ ì‘ì—… í•™ìŠµ(Multi-task learning)** êµ¬ì¡°ë¡œ ì„¤ê³„ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

| Task | Output | Loss Function |
|------|---------|----------------|
| Camera Position | (X, Y, Z) | MSELoss |
| Camera Rotation | Quaternion (x, y, z, w) | Geodesic Loss (ê°ë„ ê±°ë¦¬) |

ëª¨ë¸ êµ¬ì¡°:
- **LSTM ê¸°ë°˜ ì‹œê³„ì—´ ì¸ì½”ë”** (Bidirectional)
- **Residual Blocks Ã—3**
- **Multi-Head Self-Attention Block**
- **Position/Rotation Dual Heads**

í•™ìŠµ ì‹œ Positionê³¼ Rotationì„ ë™ì‹œì— ì˜ˆì¸¡í•˜ë©°,  
ì†ì‹¤ í•¨ìˆ˜ëŠ” `loss = MSE(Position) + Î» * Geodesic(Rotation)` í˜•íƒœë¡œ ê²°í•©ë©ë‹ˆë‹¤.

---

## ğŸ§© Data Format

`dataset.txt`ëŠ” ì•„ë˜ êµ¬ì¡°ë¡œ ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

| id | p_deg | t_deg | camPosX | camPosY | camPosZ | camEulerX_deg | camEulerY_deg | camEulerZ_deg |
|----|--------|--------|----------|----------|----------|----------------|----------------|----------------|
| 0 | 15.3 | 45.1 | 0.1 | 0.5 | 2.3 | 180 | -10 | 5 |
| ... | ... | ... | ... | ... | ... | ... | ... | ... |

- **p_deg, t_deg**: ì…ë ¥ íŒŒë¼ë¯¸í„° (cyclical encoding ì‚¬ìš©)
- **camPos\***: ì¹´ë©”ë¼ ìœ„ì¹˜
- **camEuler\***: ì¹´ë©”ë¼ íšŒì „ (deg ë‹¨ìœ„, quaternionìœ¼ë¡œ ë³€í™˜ë¨)

---

## âš™ï¸ Training Configuration

| í•­ëª© | ê°’ |
|------|-----|
| Sequence Length | 10 |
| Batch Size | 256 |
| Learning Rate | 1e-4 |
| Optimizer | AdamW |
| Scheduler | CosineAnnealingWarmRestarts |
| Epochs | 500 |
| Early Stopping | 50 |
| Lambda (Rotation Loss Weight) | 20.0 |
| Device | CUDA / CPU ìë™ ì„ íƒ |

í›ˆë ¨ ì™„ë£Œ ì‹œ `best_model_sequential.pth` ê°€ ìë™ ì €ì¥ë©ë‹ˆë‹¤.

---

## ğŸš€ How to Run

### 1ï¸âƒ£ Training
```bash
python train_multitask_attention_LSTM.py
````

* `dataset.txt` ë¡œë¶€í„° ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³ , ìŠ¤ì¼€ì¼ë§ ë° ì‹œí€€ìŠ¤ ë³€í™˜ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
* í•™ìŠµ í›„ `scalers/` í´ë”ì— í‘œì¤€í™” ì •ë³´ ì €ì¥.
* ì„±ëŠ¥ì´ í–¥ìƒëœ ëª¨ë¸ì€ ìë™ìœ¼ë¡œ `best_model_sequential.pth`ë¡œ ì €ì¥ë©ë‹ˆë‹¤.

### 2ï¸âƒ£ Evaluation

```bash
python eval_multitask_attention_LSTM.py
```

* ì €ì¥ëœ ëª¨ë¸(`best_model_sequential.pth`)ì„ ë¶ˆëŸ¬ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ìœ¼ë¡œ ì„±ëŠ¥ ì¸¡ì •.
* ì¶œë ¥:

  * **Position Mean Euclidean Error**
  * **Rotation Mean Angular Error (deg)**
  * **Per-axis Euler MAE (Roll, Pitch, Yaw)**

### 3ï¸âƒ£ Export Results

```bash
python exportResultExcel.py
```

* AI ëª¨ë¸ê³¼ Classical ëª¨ë¸(SVR, RF, Polynomial Regression)ì˜ ê²°ê³¼ë¥¼ ë¹„êµ.
* ê²°ê³¼ íŒŒì¼:

  * `predictions.xlsx` â€” ì˜ˆì¸¡ ê²°ê³¼
  * `errors.xlsx` â€” ì˜¤ì°¨ ë¶„ì„ ê²°ê³¼

---

## ğŸ§® Environment (conda)

ì•„ë˜ í‘œëŠ” **ê¸°ë³¸ ì„¤ì¹˜ ì™¸ ì¶”ê°€ëœ ì£¼ìš” íŒ¨í‚¤ì§€**ì…ë‹ˆë‹¤.

| Package      | Version | Source      |
| ------------ | ------- | ----------- |
| torch        | 2.5.1   | pytorch     |
| torchvision  | 0.20.1  | pypi        |
| torchaudio   | 2.5.1   | pypi        |
| onnx         | 1.19.1  | pypi        |
| onnxruntime  | 1.23.1  | pypi        |
| joblib       | 1.5.2   | conda-forge |
| scikit-learn | 1.7.2   | conda-forge |
| scipy        | 1.15.2  | conda-forge |
| pandas       | 2.3.3   | conda-forge |
| numpy        | 2.0.1   | conda       |
| tqdm         | 4.67.1  | conda-forge |
| matplotlib   | 3.10.6  | conda       |
| seaborn      | 0.13.2  | conda       |
| coloredlogs  | 15.0.1  | pypi        |

> ğŸ’¡ CUDA 12.1 í™˜ê²½ ê¸°ë°˜ìœ¼ë¡œ `pytorch-cuda=12.1` ì„¤ì¹˜ë¨.

---

## ğŸ“Š Output Example

**Training Log**

```
Epoch 41/500 | Val Pos Error: 0.0812 | Val Rot MAE: 1.9345Â° | LR: 0.000087
   -> Best model saved. Val Rot MAE: 1.9345Â°
```

**Evaluation Report**

```
Position Mean Euclidean Distance Error: 0.0784
Rotation Mean Angular Distance Error: 2.015Â°
MAE Euler X (Roll): 1.22Â°
MAE Euler Y (Pitch): 1.54Â°
MAE Euler Z (Yaw): 1.03Â°
```

---

## ğŸ“œ License

This project is licensed under the **MIT License**.
See the [LICENSE](LICENSE) file for details.

---

## âœ¨ Author

**ì´ì•„í˜„ (Ahyun Lee)**
ğŸ“§ [ahyun.sch@gmail.com](mailto:ahyun.sch@gmail.com)
Meta&Game.SCH

```

---

ì›í•˜ì‹ ë‹¤ë©´ ë‹¤ìŒ ë²„ì „ìœ¼ë¡œë„ ë§Œë“¤ì–´ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤:
1. ğŸ‡°ğŸ‡· **ì™„ì „ í•œê¸€ ë²„ì „** (ì—°êµ¬ ë³´ê³ ì„œ ìŠ¤íƒ€ì¼)
2. ğŸ‡ºğŸ‡¸ **ì˜ë¬¸ GitHubìš© ë²„ì „** (ë…¼ë¬¸/ê³µê°œ í”„ë¡œì íŠ¸ ìŠ¤íƒ€ì¼)
3. ğŸ§¾ **README + LICENSE ìë™ ìƒì„± ë²„ì „ (MIT í¬í•¨)**

ì–´ë–¤ í˜•ì‹ìœ¼ë¡œ ìµœì¢… ìƒì„±í• ê¹Œìš”?
```
